{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f938540",
   "metadata": {
    "tags": []
   },
   "source": [
    "# An end-to-end Vertex Training Pipeline Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3abb7a68-ed8a-40a4-b49d-10449ee45380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kfp\n",
      "  Downloading kfp-1.8.11.tar.gz (298 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.6/298.6 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py<2,>=0.9 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.0.0)\n",
      "Collecting PyYAML<6,>=5.3\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.6/636.6 KB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-cloud-storage<2,>=1.20.0\n",
      "  Downloading google_cloud_storage-1.44.0-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 KB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kubernetes<19,>=8.0.0\n",
      "  Downloading kubernetes-18.20.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-api-python-client<2,>=1.7.8\n",
      "  Downloading google_api_python_client-1.12.10-py2.py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 KB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.1\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.9/152.9 KB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-toolbelt<1,>=0.8.0\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (2.0.0)\n",
      "Collecting kfp-server-api<2.0.0,>=1.1.2\n",
      "  Downloading kfp-server-api-1.7.1.tar.gz (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jsonschema<4,>=3.0.1\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tabulate<1,>=0.8.6\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: click<9,>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (8.0.3)\n",
      "Collecting Deprecated<2,>=1.2.7\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting strip-hints<1,>=0.1.8\n",
      "  Downloading strip-hints-0.1.10.tar.gz (29 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting docstring-parser<1,>=0.7.3\n",
      "  Downloading docstring_parser-0.13.tar.gz (23 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting kfp-pipeline-spec<0.2.0,>=0.1.13\n",
      "  Downloading kfp_pipeline_spec-0.1.13-py3-none-any.whl (18 kB)\n",
      "Collecting fire<1,>=0.3.1\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.7/87.7 KB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.13.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.19.4)\n",
      "Collecting uritemplate<4,>=3.0.1\n",
      "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.9.0)\n",
      "Collecting typer<1.0,>=0.3.2\n",
      "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Collecting typing-extensions<4,>=3.7.4\n",
      "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py<2,>=0.9->kfp) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9,>=7.1.2->kfp) (4.10.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from Deprecated<2,>=1.2.7->kfp) (1.13.3)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from fire<1,>=0.3.1->kfp) (1.1.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.20.2)\n",
      "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (2.4.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (0.2.7)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (59.8.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (4.8)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.2.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.1.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.27.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (21.4.0)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (1.26.8)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2.8.2)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp) (1.3.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp) (1.2.3)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from strip-hints<1,>=0.1.8->kfp) (0.37.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp) (1.54.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (1.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client<2,>=1.7.8->kfp) (3.0.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<2,>=1.20.0->kfp) (2.0.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<2,>=1.20.0->kfp) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click<9,>=7.1.2->kfp) (3.7.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (2.21)\n",
      "Building wheels for collected packages: kfp, docstring-parser, fire, kfp-server-api, strip-hints\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp: filename=kfp-1.8.11-py3-none-any.whl size=414450 sha256=3762f274e535cc607587939bd3e0b7a6876131cb36e62f9aba0a0af8d76a0079\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/85/1e/ee/a14b49663bddf9e72d1c269cbe53970167bfabb53cadbbea3a\n",
      "  Building wheel for docstring-parser (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docstring-parser: filename=docstring_parser-0.13-py3-none-any.whl size=31866 sha256=d94f481d30442671abb707e01003fd4fc18c9bb84de66633eeef022e14b3f518\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/bd/88/3c/d1aa049309f7945178cac9fbe6561a86424f432da57c18ca0f\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=63e317f3fa49454d1a690ca1247dccd3c30b9f06d113913d7e23eee91db376a7\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
      "  Building wheel for kfp-server-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp-server-api: filename=kfp_server_api-1.7.1-py3-none-any.whl size=92618 sha256=0376d6e897656baabcaa76558a820de4d4aa7fe14dec4f9c144575f3fe73da18\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/68/3f/d5/734c0278dd6c8969cef359edcf059505a61452c5eb0e2760e1\n",
      "  Building wheel for strip-hints (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for strip-hints: filename=strip_hints-0.1.10-py2.py3-none-any.whl size=22302 sha256=a0d4a04d7d075f4cd97aee3d27a4ddc3dcb812e9dfdd02286788dcb689de370a\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/5e/14/c3/6e44e9b2545f2d570b03f5b6d38c00b7534aa8abb376978363\n",
      "Successfully built kfp docstring-parser fire kfp-server-api strip-hints\n",
      "Installing collected packages: typing-extensions, tabulate, uritemplate, strip-hints, PyYAML, kfp-pipeline-spec, fire, docstring-parser, Deprecated, requests-toolbelt, kfp-server-api, jsonschema, google-auth, typer, kubernetes, google-api-python-client, google-cloud-storage, kfp\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.0.1\n",
      "    Uninstalling typing_extensions-4.0.1:\n",
      "      Successfully uninstalled typing_extensions-4.0.1\n",
      "  Attempting uninstall: uritemplate\n",
      "    Found existing installation: uritemplate 4.1.1\n",
      "    Uninstalling uritemplate-4.1.1:\n",
      "      Successfully uninstalled uritemplate-4.1.1\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.4.0\n",
      "    Uninstalling jsonschema-4.4.0:\n",
      "      Successfully uninstalled jsonschema-4.4.0\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 2.6.0\n",
      "    Uninstalling google-auth-2.6.0:\n",
      "      Successfully uninstalled google-auth-2.6.0\n",
      "  Attempting uninstall: kubernetes\n",
      "    Found existing installation: kubernetes 21.7.0\n",
      "    Uninstalling kubernetes-21.7.0:\n",
      "      Successfully uninstalled kubernetes-21.7.0\n",
      "  Attempting uninstall: google-api-python-client\n",
      "    Found existing installation: google-api-python-client 2.36.0\n",
      "    Uninstalling google-api-python-client-2.36.0:\n",
      "      Successfully uninstalled google-api-python-client-2.36.0\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.0.0\n",
      "    Uninstalling google-cloud-storage-2.0.0:\n",
      "      Successfully uninstalled google-cloud-storage-2.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\n",
      "tfx-bsl 1.6.0 requires pyarrow<6,>=1, but you have pyarrow 6.0.1 which is incompatible.\n",
      "tfx-bsl 1.6.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<3,>=1.15.5, but you have tensorflow 2.6.3 which is incompatible.\n",
      "tensorflow 2.6.3 requires absl-py~=0.10, but you have absl-py 1.0.0 which is incompatible.\n",
      "tensorflow 2.6.3 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
      "tensorflow 2.6.3 requires wrapt~=1.12.1, but you have wrapt 1.13.3 which is incompatible.\n",
      "tensorflow-transform 1.6.0 requires pyarrow<6,>=1, but you have pyarrow 6.0.1 which is incompatible.\n",
      "tensorflow-transform 1.6.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.5, but you have tensorflow 2.6.3 which is incompatible.\n",
      "tensorflow-serving-api 2.7.0 requires tensorflow<3,>=2.7.0, but you have tensorflow 2.6.3 which is incompatible.\n",
      "cloud-tpu-client 0.10 requires google-api-python-client==1.8.0, but you have google-api-python-client 1.12.10 which is incompatible.\n",
      "apache-beam 2.35.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.4 which is incompatible.\n",
      "apache-beam 2.35.0 requires httplib2<0.20.0,>=0.8, but you have httplib2 0.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Deprecated-1.2.13 PyYAML-5.4.1 docstring-parser-0.13 fire-0.4.0 google-api-python-client-1.12.10 google-auth-1.35.0 google-cloud-storage-1.44.0 jsonschema-3.2.0 kfp-1.8.11 kfp-pipeline-spec-0.1.13 kfp-server-api-1.7.1 kubernetes-18.20.0 requests-toolbelt-0.9.1 strip-hints-0.1.10 tabulate-0.8.9 typer-0.4.0 typing-extensions-3.10.0.2 uritemplate-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install kfp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f7de01",
   "metadata": {},
   "source": [
    "Finally, check that you have correctly installed the packages. The KFP SDK version should be >=1.6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9222df33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 1.8.11\n"
     ]
    }
   ],
   "source": [
    "!python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "164ff1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from functools import partial\n",
    "\n",
    "import kfp\n",
    "import pprint\n",
    "import yaml\n",
    "from jinja2 import Template\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.compiler import compiler\n",
    "from kfp.v2.dsl import Dataset\n",
    "from kfp.v2.google.client import AIPlatformClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbe612cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id='petcircle-science-playground'\n",
    "project_number='9527'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27224ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "af_registry_location='australia-southeast1'\n",
    "af_registry_name='mlops-vertex-kit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfe4d02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "components_dir='../components/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82030efb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _load_custom_component(project_id: str,\n",
    "                           af_registry_location: str,\n",
    "                           af_registry_name: str,\n",
    "                           components_dir: str,\n",
    "                           component_name: str):\n",
    "    component_path = os.path.join(components_dir,\n",
    "                                component_name,\n",
    "                                'component.yaml.jinja')\n",
    "    with open(component_path, 'r') as f:\n",
    "        component_text = Template(f.read()).render(\n",
    "          project_id=project_id,\n",
    "          af_registry_location=af_registry_location,\n",
    "          af_registry_name=af_registry_name)\n",
    "\n",
    "    return kfp.components.load_component_from_text(component_text)\n",
    "\n",
    "load_custom_component = partial(_load_custom_component,\n",
    "                                project_id=project_id,\n",
    "                                af_registry_location=af_registry_location,\n",
    "                                af_registry_name=af_registry_name,\n",
    "                                components_dir=components_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "495502ee",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preprocess_op = load_custom_component(component_name='data_preprocess')\n",
    "train_op = load_custom_component(component_name='train_model')\n",
    "check_metrics_op = load_custom_component(component_name='check_model_metrics')\n",
    "create_endpoint_op = load_custom_component(component_name='create_endpoint')\n",
    "test_endpoint_op = load_custom_component(component_name='test_endpoint')\n",
    "deploy_model_op = load_custom_component(component_name='deploy_model')\n",
    "monitor_model_op = load_custom_component(component_name='monitor_model')\n",
    "hpo_op = load_custom_component(component_name='hpo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0026cb75",
   "metadata": {},
   "source": [
    "Then define the pipeline using the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d36a16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_region='us-central1'\n",
    "pipeline_root='gs://vertex_pipeline_demo_root_hy/pipeline_root'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "954a7af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_region='us-central1'\n",
    "#input_dataset_uri='bq://petcircle-science-playground.vertex_pipeline_demo.banknote_authentication'\n",
    "input_dataset_uri='bq://petcircle-science-playground.datalake.review_product_2013_2022'\n",
    "gcs_data_output_folder='gs://vertex_pipeline_demo_root_hy/datasets/training'\n",
    "training_data_schema='reviewtext:string;Class:int'\n",
    "\n",
    "data_pipeline_root='gs://vertex_pipeline_demo_root_hy/compute_root'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6812d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_container_image_uri=f'{af_registry_location}-docker.pkg.dev/{project_id}/{af_registry_name}/training:latest'\n",
    "serving_container_image_uri=f'{af_registry_location}-docker.pkg.dev/{project_id}/{af_registry_name}/serving:latest'\n",
    "custom_job_service_account=f'{project_number}-compute@developer.gserviceaccount.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4574529c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('us-central1-docker.pkg.dev/petcircle-science-playground/mlops-vertex-kit/training:latest',\n",
       " 'us-central1-docker.pkg.dev/petcircle-science-playground/mlops-vertex-kit/serving:latest',\n",
       " '9527-compute@developer.gserviceaccount.com')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_container_image_uri,serving_container_image_uri,custom_job_service_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a36e0154",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name='training-pipeline-template')\n",
    "def pipeline(project_id: str,\n",
    "             data_region: str,\n",
    "             gcs_data_output_folder: str,\n",
    "             input_dataset_uri: str,\n",
    "             training_data_schema: str,\n",
    "             data_pipeline_root: str,\n",
    "             \n",
    "             training_container_image_uri: str,\n",
    "             serving_container_image_uri: str,\n",
    "             custom_job_service_account: str,\n",
    "             hptune_region: str,\n",
    "             hp_config_suggestions_per_request: int,\n",
    "             hp_config_max_trials: int,\n",
    "             \n",
    "             metrics_name: str,\n",
    "             metrics_threshold: float,\n",
    "             \n",
    "             endpoint_machine_type: str,\n",
    "             endpoint_min_replica_count: int,\n",
    "             endpoint_max_replica_count: int,\n",
    "             endpoint_test_instances: str,\n",
    "             \n",
    "             output_model_file_name: str = 'model.h5',\n",
    "             machine_type: str = \"n1-standard-8\",\n",
    "             accelerator_count: int = 0,\n",
    "             accelerator_type: str = 'ACCELERATOR_TYPE_UNSPECIFIED',\n",
    "             vpc_network: str = \"\",\n",
    "             enable_model_monitoring: str = 'False',\n",
    "            task_type: str = 'training'):\n",
    "\n",
    "    preprocess_task = preprocess_op(\n",
    "      project_id=project_id,\n",
    "      data_region=data_region,\n",
    "      gcs_output_folder=gcs_data_output_folder,\n",
    "      gcs_output_format=\"CSV\",\n",
    "      task_type=task_type)\n",
    "\n",
    "    train_task = train_op(\n",
    "      project_id=project_id,\n",
    "      data_region=data_region,\n",
    "      data_pipeline_root=data_pipeline_root,\n",
    "      input_data_schema=training_data_schema,\n",
    "      training_container_image_uri=training_container_image_uri,\n",
    "      serving_container_image_uri=serving_container_image_uri,\n",
    "      custom_job_service_account=custom_job_service_account,\n",
    "      input_dataset=preprocess_task.outputs['output_dataset'],\n",
    "      output_model_file_name=output_model_file_name,\n",
    "      machine_type=machine_type,\n",
    "      accelerator_count=accelerator_count,\n",
    "      accelerator_type=accelerator_type,\n",
    "      hptune_region=hptune_region,\n",
    "      hp_config_max_trials=hp_config_max_trials,\n",
    "      hp_config_suggestions_per_request=hp_config_suggestions_per_request,\n",
    "      vpc_network=vpc_network)\n",
    "    \n",
    "    check_metrics_task = check_metrics_op(\n",
    "      metrics_name=metrics_name,\n",
    "      metrics_threshold=metrics_threshold,\n",
    "      basic_metrics=train_task.outputs['basic_metrics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5fba56",
   "metadata": {},
   "source": [
    "### Compile and run the end-to-end ML pipeline\n",
    "With our full pipeline defined, it's time to compile it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "794c18bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1266: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, \n",
    "    package_path=\"training_pipeline_job.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575b575f",
   "metadata": {},
   "source": [
    "Next, instantiate an API client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ab349ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/kfp/v2/google/client/client.py:173: FutureWarning: AIPlatformClient will be deprecated in v2.0.0. Please use PipelineJob https://googleapis.dev/python/aiplatform/latest/_modules/google/cloud/aiplatform/pipeline_jobs.html in Vertex SDK. Install the SDK using \"pip install google-cloud-aiplatform\"\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "api_client = AIPlatformClient(\n",
    "    project_id=project_id,\n",
    "    region=pipeline_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951f42d8",
   "metadata": {},
   "source": [
    "Next, kick off a pipeline run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0423941b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"reviewtext\": \"pet circle is not recommended\", \"Class\": \"0\"}, {\"reviewtext\": \"pet circle is highly recommended\", \"Class\": \"1\"}, {\"reviewtext\": \"think twice before you buy\", \"Class\": \"0\"}, {\"reviewtext\": \"great product. will buy again.\", \"Class\": \"1\"}]'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_instances = json.dumps([\n",
    "\t\t{'reviewtext': 'pet circle is not recommended',\"Class\":\"0\"},\n",
    "\t\t{'reviewtext': 'pet circle is highly recommended',\"Class\":\"1\"},\n",
    "\t\t{'reviewtext': 'think twice before you buy',\"Class\":\"0\"},\n",
    "\t\t{'reviewtext': 'great product. will buy again.',\"Class\":\"1\"}\n",
    "\t\t])\n",
    "test_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a3fe7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/training-pipeline-template-20230109004237?project=petcircle-science-playground\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_params = {\n",
    "    'project_id': project_id,\n",
    "    'data_region': data_region,\n",
    "    'gcs_data_output_folder': gcs_data_output_folder,\n",
    "    'output_model_file_name': 'model.h5',\n",
    "    'input_dataset_uri': input_dataset_uri,\n",
    "    'training_data_schema': training_data_schema,\n",
    "    'data_pipeline_root': data_pipeline_root,\n",
    "    \n",
    "    'training_container_image_uri': training_container_image_uri,\n",
    "    'serving_container_image_uri': serving_container_image_uri,\n",
    "    'custom_job_service_account': custom_job_service_account,\n",
    "    'hptune_region':\"asia-east1\",\n",
    "    'hp_config_suggestions_per_request': 5,\n",
    "    'hp_config_max_trials': 30,\n",
    "    \n",
    "    'metrics_name': 'au_prc',\n",
    "    'metrics_threshold': 0.4,\n",
    "    \n",
    "    'endpoint_machine_type': 'n1-standard-4',\n",
    "    'endpoint_min_replica_count': 1,\n",
    "    'endpoint_max_replica_count': 1,\n",
    "    'endpoint_test_instances': test_instances\n",
    "}\n",
    "\n",
    "response = api_client.create_run_from_job_spec(\n",
    "    job_spec_path=\"training_pipeline_job.json\", \n",
    "    pipeline_root=pipeline_root,\n",
    "    parameter_values=pipeline_params,\n",
    "    enable_caching=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6479f10-1848-4591-bf61-d3996f5a46bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gs://vertex_pipeline_demo_root_hy/datasets/training',\n",
       " 'us-central1-docker.pkg.dev/petcircle-science-playground/mlops-vertex-kit/serving:latest',\n",
       " 'gs://vertex_pipeline_demo_root_hy/datasets/training')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcs_data_output_folder, serving_container_image_uri, gcs_data_output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57666e57-4b3f-46a7-8905-f25a57ed5d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "project_id='petcircle-science-playground'\n",
    "data_region='us-central1'\n",
    "training_container_image_uri='us-central1-docker.pkg.dev/petcircle-science-playground/mlops-vertex-kit/training:latest'\n",
    "data_pipeline_root = 'gs://vertex_pipeline_demo_root_hy/compute_root'\n",
    "\n",
    "aiplatform.init(\n",
    "  project=project_id,\n",
    "  location=data_region,\n",
    "  staging_bucket=data_pipeline_root)\n",
    "\n",
    "\n",
    "job = aiplatform.CustomContainerTrainingJob(\n",
    "  display_name='batch_prediction',\n",
    "  location=data_region,\n",
    "  container_uri=training_container_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3e94b4-6171-4f60-90a5-f090aaff11a5",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6009c855-531b-43ee-84f4-1d5ff2769002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1646958858507"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "int(datetime.now().timestamp() * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "287c4558-6468-4c8b-ad8f-34c8a08221d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20220311003414'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().strftime('%Y%m%d%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa1bbf36-6d91-437e-adb8-ab964038be6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentiment-analysis-model-20220311003532'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'sentiment-analysis-model-{datetime.now().strftime(\"%Y%m%d%H%M%S\")}'"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m99",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m99"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
